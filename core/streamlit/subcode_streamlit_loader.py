import os
import pandas as pd
# Streamlitã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’æ¡ä»¶ä»˜ãã«å¤‰æ›´ï¼ˆãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼å›é¿ï¼‰
try:
    import streamlit as st
    ST_AVAILABLE = True
except (MemoryError, ImportError) as e:
    ST_AVAILABLE = False
    print(f"Streamlitèª­ã¿è¾¼ã¿ã‚¹ã‚­ãƒƒãƒ—: {e}")
    
    # st.cache_resourceã®ä»£æ›¿ã‚¯ãƒ©ã‚¹
    class MockCache:
        def __call__(self, func):
            return func
    
    # Streamlitãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒ¢ãƒƒã‚¯
    class MockStreamlit:
        cache_resource = MockCache()
    
    st = MockStreamlit()
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import configparser
from datetime import datetime
try:
    # æ–°æ§‹é€ ã®ãƒ­ã‚°ç®¡ç†ã‚’å„ªå…ˆä½¿ç”¨
    from src.core.logging.logger import get_logger
    LOGGER = get_logger('streamlit')
except ImportError:
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šæ—§æ§‹é€ 
    from ..config.my_logging import setup_department_logger
    LOGGER = setup_department_logger('streamlit', app_type='streamlit')
import traceback
import numpy as np

# CSSãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€é–¢æ•°
def load_css(file_name):
    try:
        with open(file_name, 'r', encoding='utf-8') as f:
            if ST_AVAILABLE:
                st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)
        LOGGER.info(f"CSSãƒ•ã‚¡ã‚¤ãƒ« '{file_name}' ã‚’æ­£å¸¸ã«èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
    except FileNotFoundError:
        LOGGER.error(f"CSSãƒ•ã‚¡ã‚¤ãƒ« '{file_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        if ST_AVAILABLE:
            st.error(f"CSSãƒ•ã‚¡ã‚¤ãƒ« '{file_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

# CSSãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
load_css("styles.css")

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•° df ã‚’å®£è¨€
df = None

# ãƒ‡ãƒ¼ã‚¿ã‚’Parquetã«ä¿å­˜ã™ã‚‹å‰ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’çµ±ä¸€ã™ã‚‹
def format_dates(df, data_types):
    for column, data_type in data_types.items():
        if column in df.columns:
            try:
                if data_type == 'date':
                    df[column] = pd.to_datetime(df[column], errors='coerce').dt.strftime('%Y/%m/%d')
                elif data_type == 'datetime':
                    df[column] = pd.to_datetime(df[column], errors='coerce').dt.strftime('%Y/%m/%d %H:%M:%S')
                LOGGER.info(f"åˆ— '{column}' ã®æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ '{data_type}' ã«å¤‰æ›ã—ã¾ã—ãŸã€‚")
            except pd.errors.OutOfBoundsDatetime as e:
                LOGGER.error(f"OutOfBoundsDatetimeã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e} (åˆ—: {column})")
                df[column] = pd.NaT  # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã«ã¯NaTã«å¤‰æ›
            except Exception as e:
                LOGGER.error(f"æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e} (åˆ—: {column})")
                df[column] = pd.NaT  # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã«ã‚‚NaTã«å¤‰æ›
    return df

# Google Sheets APIã¸ã®èªè¨¼å‡¦ç†ã‚’å…±é€šåŒ–
def get_google_sheets_client():
    config_file = 'config/settings.ini'
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰JSONèªè¨¼ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—
    from dotenv import load_dotenv
    import os
    secrets_path = os.path.join(os.getcwd(), 'config', 'secrets.env')
    load_dotenv(secrets_path)
    
    json_keyfile_path = os.getenv('JSON_KEYFILE_PATH')
    if not json_keyfile_path:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
        config = configparser.ConfigParser()
        config.read(config_file, encoding='utf-8')
        json_keyfile_path = config.get('Credentials', {}).get('json_keyfile_path', '')
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    creds = ServiceAccountCredentials.from_json_keyfile_name(json_keyfile_path, scope)
    client = gspread.authorize(creds)
    LOGGER.info("Google Sheets APIã¸ã®èªè¨¼ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
    return client

# SQLãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰èª­ã¿è¾¼ã‚€é–¢æ•°
@st.cache_resource(ttl=300)  # 5åˆ†ã«çŸ­ç¸®ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥å•é¡Œã‚’è»½æ¸›
def load_sql_list_from_spreadsheet():
    """
    Google ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰SQLãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’èª­ã¿è¾¼ã‚€
    
    Returns:
        dict: {CSVãƒ•ã‚¡ã‚¤ãƒ«å‘¼ç§°: SQLãƒ•ã‚¡ã‚¤ãƒ«å} ã®è¾æ›¸
    """
    config = configparser.ConfigParser()
    config.read('config/settings.ini', encoding='utf-8')

    spreadsheet_id = config['Spreadsheet']['spreadsheet_id']
    sheet_name = config['Spreadsheet']['eachdata_sheet']
    
    client = get_google_sheets_client()

    try:
        LOGGER.debug(f"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ '{spreadsheet_id}' ã«æ¥ç¶šä¸­...")
        spreadsheet = client.open_by_key(spreadsheet_id)
        LOGGER.debug(f"ã‚·ãƒ¼ãƒˆ '{sheet_name}' ã‚’é–‹ã„ã¦ã„ã¾ã™...")
        sheet = spreadsheet.worksheet(sheet_name)
        LOGGER.debug("ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
        data = sheet.get_all_values()
        LOGGER.info(f"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ '{spreadsheet_id}' ã®ã‚·ãƒ¼ãƒˆ '{sheet_name}' ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’æ­£å¸¸ã«å–å¾—ã—ã¾ã—ãŸã€‚")
    except gspread.exceptions.WorksheetNotFound as e:
        LOGGER.error(f"ã‚·ãƒ¼ãƒˆ '{sheet_name}' ãŒã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ '{spreadsheet_id}' ã«å­˜åœ¨ã—ã¾ã›ã‚“: {e}")
        if ST_AVAILABLE:
            st.error(f"ã‚·ãƒ¼ãƒˆ '{sheet_name}' ãŒã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ '{spreadsheet_id}' ã«å­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        return {}
    except gspread.exceptions.APIError as e:
        error_message = str(e)
        if "429" in error_message and "Quota exceeded" in error_message:
            LOGGER.warning(f"Google Sheets APIåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚5åˆ†å¾Œã«å†è©¦è¡Œã—ã¦ãã ã•ã„: {e}")
            if ST_AVAILABLE:
                st.warning("âš ï¸ Google Sheets APIã®åˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚5-10åˆ†å¾Œã«å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
                st.info("ğŸ’¡ **å¯¾å‡¦æ–¹æ³•**:\n- ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã™ã‚‹å‰ã«5åˆ†å¾…ã¤\n- ä»–ã®ã‚¿ãƒ–ã§ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’é–‹ã„ã¦ã„ã‚‹å ´åˆã¯é–‰ã˜ã‚‹")
        else:
            LOGGER.error(f"Google Sheets API ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            if ST_AVAILABLE:
                st.error(f"Google Sheets API ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return {}
    except Exception as e:
        LOGGER.error(f"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        LOGGER.debug(f"ã‚¨ãƒ©ãƒ¼ã®è©³ç´°: {type(e).__name__}: {str(e)}")
        if ST_AVAILABLE:
            st.error(f"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return {}

    if not data:
        LOGGER.warning(f"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ '{spreadsheet_id}' ã®ã‚·ãƒ¼ãƒˆ '{sheet_name}' ã¯ç©ºã§ã™ã€‚")
        if ST_AVAILABLE:
            st.warning(f"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ '{spreadsheet_id}' ã®ã‚·ãƒ¼ãƒˆ '{sheet_name}' ã¯ç©ºã§ã™ã€‚")
        return {}

    header = data[0]
    try:
        target_index = header.index('å€‹åˆ¥ãƒªã‚¹ãƒˆ')
        sql_file_name_index = header.index('sqlãƒ•ã‚¡ã‚¤ãƒ«å')
        csv_file_name_index = header.index('CSVãƒ•ã‚¡ã‚¤ãƒ«å‘¼ç§°')
    except ValueError as e:
        LOGGER.error(f"å¿…è¦ãªãƒ˜ãƒƒãƒ€ãŒã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«å­˜åœ¨ã—ã¾ã›ã‚“: {e}")
        if ST_AVAILABLE:
            st.error(f"å¿…è¦ãªãƒ˜ãƒƒãƒ€ãŒã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«å­˜åœ¨ã—ã¾ã›ã‚“: {e}")
        return {}

    records = {
        row[csv_file_name_index]: row[sql_file_name_index]
        for row in data[1:]
        if len(row) > max(target_index, sql_file_name_index, csv_file_name_index) and row[target_index].strip().lower() == 'true'
    }

    LOGGER.info(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸSQLãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã¾ã—ãŸã€‚ä»¶æ•°: {len(records)}")
    return records

# æŒ‡å®šã•ã‚ŒãŸãƒ—ãƒ«ãƒ€ã‚¦ãƒ³é¸æŠè‚¢ã«å¯¾å¿œã™ã‚‹SQLãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰.sqlæ‹¡å¼µå­ã‚’é™¤å»ã™ã‚‹é–¢æ•°
def get_sql_file_name(selected_option):
    records = load_sql_list_from_spreadsheet()
    sql_file_name = records.get(selected_option)

    if sql_file_name:
        LOGGER.info(f"é¸æŠã•ã‚ŒãŸã‚ªãƒ—ã‚·ãƒ§ãƒ³ '{selected_option}' ã«å¯¾å¿œã™ã‚‹SQLãƒ•ã‚¡ã‚¤ãƒ«å: {sql_file_name}")
        return sql_file_name.replace('.sql', '')
    else:
        LOGGER.warning(f"é¸æŠã•ã‚ŒãŸã‚ªãƒ—ã‚·ãƒ§ãƒ³ '{selected_option}' ã«å¯¾å¿œã™ã‚‹SQLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return None

# ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€å‡¦ç†ã‚’å…±é€šåŒ–ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰
@st.cache_data(ttl=600, show_spinner=False)  # 10åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def load_sheet_data_cached(sheet_name, spreadsheet_id):
    """ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãã§å–å¾—"""
    client = get_google_sheets_client()
    try:
        sheet = client.open_by_key(spreadsheet_id).worksheet(sheet_name)
        data = sheet.get_all_values()
        LOGGER.info(f"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ '{spreadsheet_id}' ã®ã‚·ãƒ¼ãƒˆ '{sheet_name}' ã‚’æ­£å¸¸ã«ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")
        return data
    except gspread.exceptions.WorksheetNotFound:
        LOGGER.error(f"ã‚·ãƒ¼ãƒˆ '{sheet_name}' ãŒã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ '{spreadsheet_id}' ã«å­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        if ST_AVAILABLE:
            st.error(f"ã‚·ãƒ¼ãƒˆ '{sheet_name}' ãŒã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ '{spreadsheet_id}' ã«å­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        return None
    except gspread.exceptions.APIError as e:
        error_message = str(e)
        if "429" in error_message and "Quota exceeded" in error_message:
            LOGGER.warning(f"Google Sheets APIåˆ¶é™ã«é”ã—ã¾ã—ãŸ: {e}")
            if ST_AVAILABLE:
                st.warning("â° Google Sheets APIã®åˆ©ç”¨åˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
        else:
            LOGGER.error(f"Google Sheets APIã‚¨ãƒ©ãƒ¼: {e}")
            if ST_AVAILABLE:
                st.error(f"Google Sheets APIã‚¨ãƒ©ãƒ¼: {e}")
        return None

def load_sheet_from_spreadsheet(sheet_name):
    config_file = 'config/settings.ini'
    config = configparser.ConfigParser()
    config.read(config_file, encoding='utf-8')
    spreadsheet_id = config['Spreadsheet']['spreadsheet_id']
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ããƒ‡ãƒ¼ã‚¿å–å¾—
    data = load_sheet_data_cached(sheet_name, spreadsheet_id)
    if data is None:
        return None
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚·ãƒ¼ãƒˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆé¢¨ã«å¤‰æ›
    class MockSheet:
        def __init__(self, data):
            self.data = data
        
        def get_all_values(self):
            return self.data
        
        def get_all_records(self):
            """ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ¬ã‚³ãƒ¼ãƒ‰å½¢å¼ã§è¿”ã™"""
            if not self.data or len(self.data) < 2:
                return []
            
            headers = self.data[0]
            records = []
            for row in self.data[1:]:
                # è¡Œã®é•·ã•ã‚’ãƒ˜ãƒƒãƒ€ãƒ¼ã«åˆã‚ã›ã‚‹
                padded_row = row + [''] * (len(headers) - len(row))
                record = dict(zip(headers, padded_row))
                records.append(record)
            return records
        
        def row_values(self, row_num):
            if row_num <= len(self.data):
                return self.data[row_num - 1]
            return []
    
    return MockSheet(data)

# é¸æŠã‚·ãƒ¼ãƒˆã®æ¡ä»¶ã‚’å–å¾—ã™ã‚‹é–¢æ•°
def get_filtered_data_from_sheet(sheet):
    try:
        header_row = sheet.row_values(1)
        cleaned_header_row = [h.strip().lower() for h in header_row]

        if len(cleaned_header_row) != len(set(cleaned_header_row)):
            raise ValueError("ãƒ˜ãƒƒãƒ€è¡Œã«é‡è¤‡ã™ã‚‹é …ç›®ãŒã‚ã‚Šã¾ã™ã€‚")

        records = sheet.get_all_records()
        LOGGER.info(f"ã‚·ãƒ¼ãƒˆã‹ã‚‰å–å¾—ã—ãŸå…¨ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(records)}")

        filtered_data = []
        for record in records:
            if record.get('çµè¾¼', '').strip().upper() == 'TRUE':
                data = {
                    'db_item': record.get('DBé …ç›®', '').strip(),
                    'table_name': record.get('TABLE_NAME', '').strip(),
                    'data_item': record.get('DATA_ITEM', '').strip(),
                    'input_type': record.get('å…¥åŠ›æ–¹å¼', '').strip(),
                    'options': [option.split(' ') for option in record.get('é¸æŠé …ç›®', '').split('\n') if option.strip()]
                }
                filtered_data.append(data)

        LOGGER.info(f"çµè¾¼æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(filtered_data)}")
        return filtered_data
    except Exception as e:
        LOGGER.error(f"é¸æŠã‚·ãƒ¼ãƒˆã‹ã‚‰æ¡ä»¶ã‚’å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.error(f"é¸æŠã‚·ãƒ¼ãƒˆã‹ã‚‰æ¡ä»¶ã‚’å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return []

# å‹•çš„ãªå…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ä½œæˆã™ã‚‹é–¢æ•°å†…ã®ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹éƒ¨åˆ†
def create_dynamic_input_fields(data):
    input_fields = {}
    input_fields_types = {}
    options_dict = {}

    if not data:
        st.error("æŒ‡å®šã•ã‚Œã¦ã„ã‚‹é …ç›®ãŒã‚ã‚Šã¾ã›ã‚“")
        LOGGER.warning("æŒ‡å®šã•ã‚Œã¦ã„ã‚‹é …ç›®ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return input_fields, input_fields_types, options_dict

    num_columns = 3
    num_items = len(data)
    items_per_column = (num_items + num_columns - 1) // num_columns

    columns = st.columns(num_columns)

    for i, item in enumerate(data):
        column_index = i // items_per_column
        with columns[column_index]:
            label_text = item['db_item']

            if item['input_type'] == 'FA':
                input_fields[item['db_item']] = st.text_input(label_text, key=f"input_{item['db_item']}")
                input_fields_types[item['db_item']] = 'FA'
                LOGGER.debug(f"FAå…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ä½œæˆã—ã¾ã—ãŸ: {item['db_item']}")

            elif item['input_type'] == 'ãƒ—ãƒ«ãƒ€ã‚¦ãƒ³':
                options = ['-'] + list(set([option[1] for option in item['options'] if len(option) > 1]))
                input_fields[item['db_item']] = st.selectbox(label_text, options, key=f"input_{item['db_item']}")
                input_fields_types[item['db_item']] = 'ãƒ—ãƒ«ãƒ€ã‚¦ãƒ³'
                options_dict[item['db_item']] = item['options']
                LOGGER.debug(f"ãƒ—ãƒ«ãƒ€ã‚¦ãƒ³å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ä½œæˆã—ã¾ã—ãŸ: {item['db_item']} with options {options}")

            elif item['input_type'] == 'ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³':
                options = [option[1] for option in item['options'] if len(option) > 1]
                radio_key = f"radio_{item['db_item']}"
                clear_key = f"clear_radio_{item['db_item']}"

                if st.session_state.get(clear_key, False):
                    st.session_state[radio_key] = None
                    st.session_state[clear_key] = False
                    LOGGER.debug(f"ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ: {item['db_item']}")

                st.text(label_text)  # ãƒ•ãƒªãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã‚¿ã‚¤ãƒˆãƒ«ã¨åŒã˜ã‚µã‚¤ã‚ºã¨æ–‡å­—ã‚¿ã‚¤ãƒ—ã«çµ±ä¸€
                if options:
                    radio_index = st.radio("", range(len(options)), format_func=lambda i: options[i], index=st.session_state.get(radio_key, 0), key=radio_key)
                    input_fields[item['db_item']] = options[radio_index] if radio_index is not None else None
                    input_fields_types[item['db_item']] = 'ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³'
                    options_dict[item['db_item']] = item['options']
                    LOGGER.debug(f"ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ä½œæˆã—ã¾ã—ãŸ: {item['db_item']} with options {options}")
                else:
                    LOGGER.warning(f"ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ '{item['db_item']}' ã«ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

            elif item['input_type'] == 'ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹':
                st.text(label_text)  # ãƒ•ãƒªãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã‚¿ã‚¤ãƒˆãƒ«ã¨åŒã˜ã‚µã‚¤ã‚ºã¨æ–‡å­—ã‚¿ã‚¤ãƒ—ã«çµ±ä¸€
                checkbox_values = {}
                for option in item['options']:
                    if len(option) > 1:
                        checkbox_values[option[1]] = st.checkbox(option[1], key=f"checkbox_{item['db_item']}_{option[0]}")
                input_fields[item['db_item']] = checkbox_values
                input_fields_types[item['db_item']] = 'ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹'
                options_dict[item['db_item']] = item['options']  # ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä¿å­˜
                LOGGER.debug(f"ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ä½œæˆã—ã¾ã—ãŸ: {item['db_item']} with options {options_dict[item['db_item']]}")

            elif item['input_type'] == 'Date':
                start_date = st.date_input(f"{label_text} é–‹å§‹æ—¥", key=f"start_date_{item['db_item']}", value=None)
                end_date = st.date_input(f"{label_text} çµ‚äº†æ—¥", key=f"end_date_{item['db_item']}", value=None)
                input_fields[item['db_item']] = {'start_date': start_date, 'end_date': end_date}
                input_fields_types[item['db_item']] = 'date'
                LOGGER.debug(f"Dateå…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ä½œæˆã—ã¾ã—ãŸ: {item['db_item']} with start_date={start_date}, end_date={end_date}")

            elif item['input_type'] == 'Datetime':
                start_date = st.date_input(f"{label_text} é–‹å§‹æ—¥", key=f"start_datetime_{item['db_item']}", value=None)
                end_date = st.date_input(f"{label_text} çµ‚äº†æ—¥", key=f"end_datetime_{item['db_item']}", value=None)
                input_fields[item['db_item']] = {'start_date': start_date, 'end_date': end_date}
                input_fields_types[item['db_item']] = 'datetime'
                LOGGER.debug(f"Datetimeå…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ä½œæˆã—ã¾ã—ãŸ: {item['db_item']} with start_date={start_date}, end_date={end_date}")

    st.session_state['input_fields'] = input_fields
    st.session_state['input_fields_types'] = input_fields_types
    st.session_state['options_dict'] = options_dict

    return input_fields, input_fields_types, options_dict

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚’åˆæœŸåŒ–ã™ã‚‹é–¢æ•°
def initialize_session_state():
    if 'selected_sql_file' not in st.session_state:
        st.session_state['selected_sql_file'] = None
        LOGGER.debug("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆ 'selected_sql_file' ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸã€‚")
    if 'df' not in st.session_state:
        st.session_state['df'] = None
        LOGGER.debug("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆ 'df' ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸã€‚")
    if 'limit' not in st.session_state:
        st.session_state['limit'] = 20  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’20ã«å¤‰æ›´
        LOGGER.debug("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆ 'limit' ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸã€‚")
    if 'total_records' not in st.session_state:
        st.session_state['total_records'] = 0
        LOGGER.debug("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆ 'total_records' ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸã€‚")
    if 'selected_rows' not in st.session_state:
        st.session_state['selected_rows'] = 20  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’20ã«å¤‰æ›´
        LOGGER.debug("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆ 'selected_rows' ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸã€‚")
    if 'input_fields' not in st.session_state:
        st.session_state['input_fields'] = {}
        LOGGER.debug("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆ 'input_fields' ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸã€‚")
    if 'input_fields_types' not in st.session_state:
        st.session_state['input_fields_types'] = {}
        LOGGER.debug("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆ 'input_fields_types' ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸã€‚")
    if 'options_dict' not in st.session_state:
        st.session_state['options_dict'] = {}
        LOGGER.debug("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆ 'options_dict' ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸã€‚")
    if 'current_page' not in st.session_state:
        st.session_state['current_page'] = 1
        LOGGER.debug("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆ 'current_page' ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸã€‚")
    if 'last_selected_table' not in st.session_state:
        st.session_state['last_selected_table'] = None
        LOGGER.debug("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆ 'last_selected_table' ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸã€‚")

# ãƒ†ã‚­ã‚¹ãƒˆã‚’çœç•¥è¡¨ç¤ºã™ã‚‹é–¢æ•°
def truncate_text(text, max_length=35):
    if len(str(text)) > max_length:
        return str(text)[:max_length] + "..."
    return text

def load_and_filter_parquet(parquet_file_path, input_fields, input_fields_types, options_dict):
    try:
        df = pd.read_parquet(parquet_file_path)
        LOGGER.info(f"Parquetãƒ•ã‚¡ã‚¤ãƒ« '{parquet_file_path}' ã‚’æ­£å¸¸ã«èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
        
        # None ã¾ãŸã¯ nan å€¤ã‚’å„åˆ—ã®ãƒ‡ãƒ¼ã‚¿å‹ã«å¿œã˜ãŸå€¤ã«ç½®æ›
        for column in df.columns:
            if df[column].dtype == 'object':
                df[column] = df[column].fillna('')
            elif df[column].dtype == 'Int64':
                df[column] = df[column].fillna(0)  # Int64å‹ã®åˆ—ã¯NaNã‚’0ã«ç½®æ›
            elif df[column].dtype == 'float64':
                df[column] = df[column].fillna(np.nan)  # float64å‹ã®åˆ—ã¯NaNã‚’np.nanã«ç½®æ›
            else:
                df[column] = df[column].fillna(pd.NA)  # ãã®ä»–ã®å‹ã¯pd.NAã«ç½®æ›
        LOGGER.info("NaNå€¤ã‚’é©åˆ‡ã«ç½®æ›ã—ã¾ã—ãŸã€‚")

        # ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã®é©ç”¨
        for field, value in input_fields.items():
            LOGGER.info(f"ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ - {field}: {value}")  # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã‚’ãƒ­ã‚°ã«è¨˜éŒ²

            if input_fields_types[field] == 'FA' and value:
                if df[field].dtype == 'Int64':
                    try:
                        df = df[df[field] == int(value)]
                        LOGGER.debug(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° - {field} == {int(value)}")
                    except ValueError:
                        LOGGER.warning(f"ç„¡åŠ¹ãªæ•´æ•°å€¤ '{value}' ãŒå…¥åŠ›ã•ã‚Œã¾ã—ãŸã€‚ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                else:
                    df = df[df[field].astype(str).str.contains(value, na=False)]
                    LOGGER.debug(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° - {field} ã« '{value}' ã‚’å«ã‚€")

            elif input_fields_types[field] == 'ãƒ—ãƒ«ãƒ€ã‚¦ãƒ³' and value != '-':
                df = df[df[field] == value]
                LOGGER.debug(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° - {field} == '{value}'")

            elif input_fields_types[field] == 'ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³' and value:
                df = df[df[field] == value]
                LOGGER.debug(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° - {field} == '{value}'")

            elif input_fields_types[field] == 'ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹':
                # å…ƒã®æŒ™å‹•ã«æˆ»ã™ï¼šé¸æŠãƒ©ãƒ™ãƒ«ã§ãã®ã¾ã¾æ¯”è¼ƒ
                selected_labels = [label for label, selected in value.items() if selected]
                if selected_labels:
                    df[field] = df[field].astype(str)
                    df = df[df[field].isin(selected_labels)]
                    LOGGER.debug(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° - {field} ã«é¸æŠã•ã‚ŒãŸãƒ©ãƒ™ãƒ« {selected_labels} ãŒå«ã¾ã‚Œã‚‹")

            elif input_fields_types[field] in ['date', 'datetime']:
                start_date = value.get('start_date')
                end_date = value.get('end_date')
                
                df[field] = pd.to_datetime(df[field], errors='coerce')
                LOGGER.debug(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° - {field} ã‚’datetimeå‹ã«å¤‰æ›ã—ã¾ã—ãŸã€‚")
                
                if start_date and end_date:
                    start_datetime = pd.to_datetime(start_date).floor('D')
                    end_datetime = pd.to_datetime(end_date).replace(hour=23, minute=59, second=59, microsecond=999999)
                    df = df[(df[field] >= start_datetime) & (df[field] <= end_datetime)]
                    LOGGER.debug(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° - {field} ã‚’ {start_datetime} ã‹ã‚‰ {end_datetime} ã¾ã§ã«åˆ¶é™ã—ã¾ã—ãŸã€‚")
                elif start_date:
                    start_datetime = pd.to_datetime(start_date).floor('D')
                    df = df[df[field] >= start_datetime]
                    LOGGER.debug(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° - {field} ã‚’ {start_datetime} ä»¥é™ã«åˆ¶é™ã—ã¾ã—ãŸã€‚")
                elif end_date:
                    end_datetime = pd.to_datetime(end_date).replace(hour=23, minute=59, second=59, microsecond=999999)
                    df = df[df[field] <= end_datetime]
                    LOGGER.debug(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° - {field} ã‚’ {end_datetime} ä»¥å‰ã«åˆ¶é™ã—ã¾ã—ãŸã€‚")
                
        if df.empty:
            LOGGER.warning("ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®DataFrameãŒç©ºã§ã™ã€‚")
            return pd.DataFrame()
        else:
            LOGGER.info("ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®DataFrameãŒå–å¾—ã•ã‚Œã¾ã—ãŸã€‚")
            return df.sort_index(ascending=False)  # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã«é™é †ã«ä¸¦ã¹æ›¿ãˆ
    except Exception as e:
        LOGGER.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        LOGGER.debug(traceback.format_exc())
        return None

# Parquetãƒ•ã‚¡ã‚¤ãƒ«ã®é¸æŠæ™‚ã®å‡¦ç†
def on_sql_file_change(sql_files_dict):
    try:
        selected_display_name = st.session_state.get('selected_display_name')
        if not selected_display_name:
            LOGGER.warning("é¸æŠã•ã‚ŒãŸSQLãƒ•ã‚¡ã‚¤ãƒ«åãŒã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«å­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
            return

        st.session_state['selected_sql_file'] = sql_files_dict.get(selected_display_name)
        sql_file_name = get_sql_file_name(selected_display_name)
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‘ã‚¹ã‚’å–å¾—
        try:
            from src.core.config.settings import AppConfig
            app_config = AppConfig.from_config_file('config/settings.ini')
            csv_base_path = app_config.paths.csv_base_path
        except ImportError:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šæ—§æ§‹é€ 
            import configparser
            config = configparser.ConfigParser()
            config.read('config/settings.ini', encoding='utf-8')
            csv_base_path = config['Paths']['csv_base_path']
        
        parquet_file_path = os.path.join(csv_base_path, f"{sql_file_name}.parquet")

        if os.path.exists(parquet_file_path):
            df = pd.read_parquet(parquet_file_path)
            df = df.sort_index(ascending=False)  # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®é™é †ã§ä¸¦ã¹æ›¿ãˆ
            st.session_state['df'] = df
            st.session_state['total_records'] = len(df)
            LOGGER.info(f"Parquetãƒ•ã‚¡ã‚¤ãƒ« '{parquet_file_path}' ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")
        else:
            st.error(f"Parquetãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {parquet_file_path}")
            LOGGER.error(f"Parquetãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {parquet_file_path}")
    except Exception as e:
        LOGGER.error(f"on_sql_file_changeé–¢æ•°å†…ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.error(f"Error in on_sql_file_change: {e}")

def calculate_offset(page_number, page_size):
    return (page_number - 1) * page_size

def on_limit_change():
    st.session_state['limit'] = st.session_state.get('rows_selectbox', 20)
    st.session_state['selected_rows'] = st.session_state['limit']
    df = st.session_state.get('df')
    if df is not None:
        page_number = st.session_state.get('current_page', 1)  # ç¾åœ¨ã®ãƒšãƒ¼ã‚¸ç•ªå·ã‚’å–å¾—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯1ï¼‰
        st.session_state['df_view'] = load_and_prepare_data(df, page_number, st.session_state['selected_rows'])
        LOGGER.info(f"è¡¨ç¤ºè¡Œæ•°ã‚’ {st.session_state['selected_rows']} ã«å¤‰æ›´ã—ã¾ã—ãŸã€‚")

# ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’åˆ¶é™ã—ã¦æº–å‚™ã™ã‚‹é–¢æ•°
def load_and_prepare_data(df, page_number, page_size):
    if df is None:
        LOGGER.info("DataFrameãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        return pd.DataFrame()  # ç©ºã®DataFrameã‚’è¿”ã™
    offset = calculate_offset(page_number, page_size)
    limited_df = df.iloc[offset:offset + page_size]  # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®é™é †ã¯æ—¢ã«ã‚½ãƒ¼ãƒˆæ¸ˆã¿ã¨ä»®å®š
    LOGGER.info(f"ãƒšãƒ¼ã‚¸ {page_number} ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")
    return limited_df

# æ¤œç´¢ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸå ´åˆã®å‡¦ç†
def on_search_click():
    input_fields = st.session_state.get('input_fields', {})
    input_fields_types = st.session_state.get('input_fields_types', {})
    selected_display_name = st.session_state.get('selected_display_name')
    if not selected_display_name:
        st.error("SQLãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        LOGGER.warning("SQLãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return

    sql_file_name = get_sql_file_name(selected_display_name)
    if not sql_file_name:
        st.error(f"é¸æŠã•ã‚ŒãŸã‚ªãƒ—ã‚·ãƒ§ãƒ³ '{selected_display_name}' ã«å¯¾å¿œã™ã‚‹SQLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        LOGGER.error(f"é¸æŠã•ã‚ŒãŸã‚ªãƒ—ã‚·ãƒ§ãƒ³ '{selected_display_name}' ã«å¯¾å¿œã™ã‚‹SQLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return

    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‘ã‚¹ã‚’å–å¾—
    try:
        from src.core.config.settings import AppConfig
        app_config = AppConfig.from_config_file('config/settings.ini')
        csv_base_path = app_config.paths.csv_base_path
    except ImportError:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šæ—§æ§‹é€ 
        import configparser
        config = configparser.ConfigParser()
        config.read('config/settings.ini', encoding='utf-8')
        csv_base_path = config['Paths']['csv_base_path']
    
    parquet_file_path = os.path.join(csv_base_path, f"{sql_file_name}.parquet")

    if os.path.exists(parquet_file_path):
        df = load_and_filter_parquet(parquet_file_path, input_fields, input_fields_types, st.session_state.get('options_dict', {}))
        if df is None:
            st.error("ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¾ãŸã¯ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            LOGGER.error("ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¾ãŸã¯ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        elif df.empty:
            st.error("è©²å½“ã®æ¤œç´¢çµæœã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            LOGGER.info("è©²å½“ã®æ¤œç´¢çµæœã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            st.session_state['df'] = df
            st.session_state['total_records'] = len(df)
            st.session_state['current_page'] = 1  # ãƒšãƒ¼ã‚¸ã‚’ãƒªã‚»ãƒƒãƒˆ
            st.session_state['df_view'] = load_and_prepare_data(df, 1, st.session_state['selected_rows'])
            LOGGER.info(f"æ¤œç´¢çµæœã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(df)}")
    else:
        st.error(f"Parquetãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {parquet_file_path}")
        LOGGER.error(f"Parquetãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {parquet_file_path}")

def get_parquet_file_last_modified(parquet_file_path):
    if os.path.exists(parquet_file_path):
        last_modified_timestamp = os.path.getmtime(parquet_file_path)
        last_modified_datetime = datetime.fromtimestamp(last_modified_timestamp)
        last_modified_str = last_modified_datetime.strftime("%Y-%m-%d %H:%M:%S")
        LOGGER.info(f"Parquetãƒ•ã‚¡ã‚¤ãƒ« '{parquet_file_path}' ã®æœ€çµ‚æ›´æ–°æ—¥æ™‚: {last_modified_str}")
        return last_modified_str
    else:
        LOGGER.warning(f"Parquetãƒ•ã‚¡ã‚¤ãƒ« '{parquet_file_path}' ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        return None

# Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ¡ã‚¤ãƒ³éƒ¨åˆ†
def main():
    st.title("SQLãƒ‡ãƒ¼ã‚¿ãƒ“ãƒ¥ãƒ¼ã‚¢")

    initialize_session_state()

    # SQLãƒ•ã‚¡ã‚¤ãƒ«ã®é¸æŠ
    sql_files_dict = load_sql_list_from_spreadsheet()
    if not sql_files_dict:
        st.warning("å®Ÿè¡Œå¯¾è±¡ã®SQLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return

    selected_display_names = list(sql_files_dict.keys())
    selected_display_name = st.selectbox("SQLãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„", [""] + selected_display_names, key='selected_display_name')

    if selected_display_name:
        on_sql_file_change(sql_files_dict)

    # é¸æŠã•ã‚ŒãŸSQLãƒ•ã‚¡ã‚¤ãƒ«ã«åŸºã¥ã„ã¦æ¡ä»¶å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã‚’è¡¨ç¤º
    if st.session_state.get('selected_sql_file') and st.session_state.get('df') is not None:
        sheet_name = st.session_state.get('last_selected_table')
        if sheet_name:
            sheet = load_sheet_from_spreadsheet(sheet_name)
            if sheet:
                filtered_data = get_filtered_data_from_sheet(sheet)
                input_fields, input_fields_types, options_dict = create_dynamic_input_fields(filtered_data)
                st.session_state['input_fields'] = input_fields
                st.session_state['input_fields_types'] = input_fields_types
                st.session_state['options_dict'] = options_dict

                if st.button("æ¤œç´¢", on_click=on_search_click):
                    LOGGER.info("æ¤œç´¢ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚Œã¾ã—ãŸã€‚")

        # ãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºã‚»ã‚¯ã‚·ãƒ§ãƒ³
        if st.session_state.get('df_view') is not None:
            df_view = st.session_state['df_view']
            total_records = st.session_state.get('total_records', 0)

            st.write(f"ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {total_records}")
            st.dataframe(df_view)

            # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³
            if total_records > st.session_state['selected_rows']:
                num_pages = (total_records + st.session_state['selected_rows'] - 1) // st.session_state['selected_rows']
                current_page = st.session_state.get('current_page', 1)
                col1, col2, col3 = st.columns(3)

                with col2:
                    page = st.number_input("ãƒšãƒ¼ã‚¸ç•ªå·", min_value=1, max_value=num_pages, value=current_page, step=1, key='current_page_input')
                    if st.button("ç§»å‹•"):
                        st.session_state['current_page'] = page
                        st.session_state['df_view'] = load_and_prepare_data(st.session_state['df'], page, st.session_state['selected_rows'])
                        LOGGER.info(f"ãƒšãƒ¼ã‚¸ {page} ã«ç§»å‹•ã—ã¾ã—ãŸã€‚")

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«è¨­å®š
    with st.sidebar:
        st.header("è¨­å®š")
        rows_options = [10, 20, 50, 100]
        selected_rows = st.selectbox("è¡¨ç¤ºã™ã‚‹è¡Œæ•°", rows_options, index=rows_options.index(st.session_state.get('selected_rows', 20)), key='rows_selectbox', on_change=on_limit_change)

if __name__ == "__main__":
    main()
