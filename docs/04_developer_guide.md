# é–‹ç™ºè€…å‘ã‘ã‚¬ã‚¤ãƒ‰ï¼ˆæœ€æ–°ç‰ˆï¼‰

> **ğŸ¯ é‡è¦æ›´æ–°**: è¨­å®šçµ±ä¸€ã¨secrets.envç§»è¡Œã«ã‚ˆã‚Šã€é–‹ç™ºãƒ•ãƒ­ãƒ¼ãŒç°¡ç´ åŒ–ã•ã‚Œã¾ã—ãŸã€‚

## é–‹ç™ºç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### 1. å¿…è¦ãªãƒ„ãƒ¼ãƒ«
- **Python**: 3.9+
- **IDE**: VSCode / PyCharm æ¨å¥¨
- **Git**: ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†
- **PowerShell**: ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ

### 2. é–‹ç™ºç”¨ä¾å­˜é–¢ä¿‚
```txt
# requirements-dev.txt
# åŸºæœ¬ä¾å­˜é–¢ä¿‚
-r requirements.txt

# é–‹ç™ºç”¨ãƒ„ãƒ¼ãƒ«
pytest>=7.0.0
flake8>=4.0.0
black>=22.0.0
mypy>=0.950
pre-commit>=2.17.0
pytest-cov>=3.0.0
```

### 3. IDEè¨­å®šï¼ˆVSCodeï¼‰
```json
// .vscode/settings.json
{
    "python.defaultInterpreterPath": "./venv/Scripts/python.exe",
    "python.linting.enabled": true,
    "python.linting.flake8Enabled": true,
    "python.formatting.provider": "black",
    "python.testing.pytestEnabled": true,
    "python.testing.pytestArgs": ["tests/"]
}
```

## ã‚³ãƒ¼ãƒ‰ã‚¹ã‚¿ã‚¤ãƒ«ãƒ»è¦ç´„

### 1. Python ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„
- **PEP 8** ã«æº–æ‹ 
- **Black** ã«ã‚ˆã‚‹è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
- **flake8** ã«ã‚ˆã‚‹é™çš„è§£æ

### 2. å‘½åè¦ç´„
```python
# ãƒ•ã‚¡ã‚¤ãƒ«å: snake_case
user_data_processor.py

# ã‚¯ãƒ©ã‚¹å: PascalCase
class DataProcessor:
    pass

# é–¢æ•°ãƒ»å¤‰æ•°å: snake_case
def process_user_data():
    user_count = 100

# å®šæ•°: UPPER_SNAKE_CASE
MAX_RETRY_COUNT = 3
```

### 3. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
```python
def process_sql_file(sql_file: str, output_format: str = 'csv') -> bool:
    """
    SQLãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’å‡ºåŠ›ã™ã‚‹
    
    Args:
        sql_file (str): SQLãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        output_format (str): å‡ºåŠ›å½¢å¼ ('csv' ã¾ãŸã¯ 'parquet')
    
    Returns:
        bool: å‡¦ç†æˆåŠŸæ™‚Trueã€å¤±æ•—æ™‚False
    
    Raises:
        FileNotFoundError: SQLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
        DatabaseConnectionError: DBæ¥ç¶šã‚¨ãƒ©ãƒ¼ã®å ´åˆ
    """
    pass
```

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 

### ç¾åœ¨ã®æ§‹é€ 
```
sourcecode/
â”œâ”€â”€ main.py                    # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
â”œâ”€â”€ common_exe_functions.py    # å…±é€šå‡¦ç†ï¼ˆ1270è¡Œï¼‰
â”œâ”€â”€ subcode_loader.py          # ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚³ã‚¢ï¼ˆå·¨å¤§ï¼‰
â”œâ”€â”€ config_loader.py           # è¨­å®šèª­ã¿è¾¼ã¿
â”œâ”€â”€ my_logging.py              # ãƒ­ã‚°ç®¡ç†
â”œâ”€â”€ streamlit_app.py           # WebUI
â”œâ”€â”€ run.ps1                    # å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â””â”€â”€ config.ini                 # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
```

### æ¨å¥¨æ§‹é€ ï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å¾Œï¼‰
```
src/
â”œâ”€â”€ batch_system/              # å®šæœŸãƒãƒƒãƒã‚·ã‚¹ãƒ†ãƒ 
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ processors/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ csv_processor.py
â”‚   â”‚   â””â”€â”€ spreadsheet_processor.py
â”‚   â””â”€â”€ config/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ batch_config.py
â”œâ”€â”€ streamlit_system/          # ã‚¹ãƒˆãƒŸãƒ³ã‚·ã‚¹ãƒ†ãƒ 
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ data_sources/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ parquet_generator.py
â”‚   â””â”€â”€ ui/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ components.py
â”œâ”€â”€ core/                      # å…±é€šã‚³ã‚¢æ©Ÿèƒ½
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ connection.py
â”‚   â”‚   â””â”€â”€ ssh_tunnel.py
â”‚   â”œâ”€â”€ google_api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ drive_client.py
â”‚   â”‚   â””â”€â”€ sheets_client.py
â”‚   â”œâ”€â”€ logging/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ logger.py
â”‚   â””â”€â”€ config/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ settings.py
â”œâ”€â”€ utils/                     # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ file_utils.py
â”‚   â””â”€â”€ data_utils.py
â””â”€â”€ tests/                     # ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_batch_system/
    â”œâ”€â”€ test_streamlit_system/
    â”œâ”€â”€ test_core/
    â””â”€â”€ fixtures/
```

## ä¸»è¦ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®è¨­è¨ˆ

### 1. ãƒ‡ãƒ¼ã‚¿å‡¦ç†åŸºç›¤
```python
# core/data_processor.py
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional
import pandas as pd

class DataProcessor(ABC):
    """ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®åŸºåº•ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config: Dict[str, Any], logger):
        self.config = config
        self.logger = logger
    
    @abstractmethod
    def process(self, source: str) -> pd.DataFrame:
        """ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®æŠ½è±¡ãƒ¡ã‚½ãƒƒãƒ‰"""
        pass

class SQLDataProcessor(DataProcessor):
    """SQLå®Ÿè¡Œã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿å‡¦ç†"""
    
    def process(self, sql_file: str) -> pd.DataFrame:
        sql_query = self._load_sql_file(sql_file)
        return self._execute_query(sql_query)
    
    def _load_sql_file(self, file_path: str) -> str:
        """SQLãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿"""
        pass
    
    def _execute_query(self, query: str) -> pd.DataFrame:
        """SQLã‚¯ã‚¨ãƒªã®å®Ÿè¡Œ"""
        pass
```

### 2. è¨­å®šç®¡ç†
```python
# core/config/settings.py
from dataclasses import dataclass
from typing import Dict, Optional
import os

@dataclass
class DatabaseConfig:
    host: str
    port: int
    user: str
    password: str
    database: str

@dataclass
class GoogleAPIConfig:
    credentials_file: str
    spreadsheet_id: str
    drive_folder_id: str

@dataclass
class AppConfig:
    environment: str
    debug: bool
    database: DatabaseConfig
    google_api: GoogleAPIConfig
    
    @classmethod
    def from_env(cls) -> 'AppConfig':
        """ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
        return cls(
            environment=os.getenv('APP_ENV', 'development'),
            debug=os.getenv('DEBUG', 'False').lower() == 'true',
            database=DatabaseConfig(
                host=os.getenv('DB_HOST'),
                port=int(os.getenv('DB_PORT', '3306')),
                user=os.getenv('DB_USER'),
                password=os.getenv('DB_PASSWORD'),
                database=os.getenv('DB_NAME')
            ),
            google_api=GoogleAPIConfig(
                credentials_file=os.getenv('GOOGLE_CREDENTIALS'),
                spreadsheet_id=os.getenv('SPREADSHEET_ID'),
                drive_folder_id=os.getenv('DRIVE_FOLDER_ID')
            )
        )
```

### 3. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
```python
# core/exceptions.py
class CSVToolException(Exception):
    """åŸºåº•ä¾‹å¤–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, message: str, error_code: str = None):
        super().__init__(message)
        self.error_code = error_code
        self.message = message

class DatabaseConnectionError(CSVToolException):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼"""
    pass

class GoogleAPIError(CSVToolException):
    """Google APIé–¢é€£ã‚¨ãƒ©ãƒ¼"""
    pass

class SQLExecutionError(CSVToolException):
    """SQLå®Ÿè¡Œã‚¨ãƒ©ãƒ¼"""
    pass

# core/error_handler.py
class ErrorHandler:
    def __init__(self, logger, notifier=None):
        self.logger = logger
        self.notifier = notifier
    
    def handle_error(self, error: Exception, context: Dict = None) -> Dict:
        """çµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"""
        error_info = {
            'error_type': type(error).__name__,
            'message': str(error),
            'context': context or {}
        }
        
        self.logger.error(f"ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {error_info}")
        
        if self.notifier and isinstance(error, CSVToolException):
            self.notifier.send_error_notification(error_info)
        
        return error_info
```

## ãƒ†ã‚¹ãƒˆæˆ¦ç•¥

### 1. ãƒ†ã‚¹ãƒˆæ§‹æˆ
```python
# tests/conftest.py
import pytest
from unittest.mock import Mock
from core.config.settings import AppConfig

@pytest.fixture
def mock_config():
    """ãƒ†ã‚¹ãƒˆç”¨è¨­å®š"""
    return AppConfig(
        environment='test',
        debug=True,
        database=Mock(),
        google_api=Mock()
    )

@pytest.fixture
def sample_dataframe():
    """ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ """
    import pandas as pd
    return pd.DataFrame({
        'id': [1, 2, 3],
        'name': ['test1', 'test2', 'test3']
    })
```

### 2. å˜ä½“ãƒ†ã‚¹ãƒˆä¾‹
```python
# tests/test_core/test_data_processor.py
import pytest
from unittest.mock import Mock, patch
from core.data_processor import SQLDataProcessor

class TestSQLDataProcessor:
    
    def test_process_success(self, mock_config):
        """æ­£å¸¸ç³»ãƒ†ã‚¹ãƒˆ"""
        processor = SQLDataProcessor(mock_config, Mock())
        
        with patch.object(processor, '_load_sql_file') as mock_load:
            with patch.object(processor, '_execute_query') as mock_execute:
                mock_load.return_value = "SELECT * FROM test"
                mock_execute.return_value = Mock()
                
                result = processor.process('test.sql')
                
                assert result is not None
                mock_load.assert_called_once_with('test.sql')
                mock_execute.assert_called_once()
    
    def test_process_file_not_found(self, mock_config):
        """ç•°å¸¸ç³»ãƒ†ã‚¹ãƒˆ - ãƒ•ã‚¡ã‚¤ãƒ«æœªç™ºè¦‹"""
        processor = SQLDataProcessor(mock_config, Mock())
        
        with patch.object(processor, '_load_sql_file') as mock_load:
            mock_load.side_effect = FileNotFoundError("File not found")
            
            with pytest.raises(FileNotFoundError):
                processor.process('nonexistent.sql')
```

### 3. çµ±åˆãƒ†ã‚¹ãƒˆä¾‹
```python
# tests/test_integration/test_batch_workflow.py
import pytest
from batch_system.main import BatchProcessor

class TestBatchWorkflow:
    
    @pytest.mark.integration
    def test_full_batch_execution(self, test_database, test_config):
        """ãƒãƒƒãƒå‡¦ç†å…¨ä½“ã®ãƒ†ã‚¹ãƒˆ"""
        processor = BatchProcessor(test_config)
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        self._setup_test_data(test_database)
        
        # ãƒãƒƒãƒå®Ÿè¡Œ
        result = processor.run()
        
        # çµæœæ¤œè¨¼
        assert result.success
        assert result.processed_files > 0
        
        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
        output_files = self._get_output_files()
        assert len(output_files) > 0
```

## ãƒ‡ãƒãƒƒã‚°ãƒ»ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### 1. ãƒ­ã‚°è¨­å®šï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
```python
# core/logging/debug_logger.py
import logging
import sys

def setup_debug_logging():
    """ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ­ã‚°è¨­å®š"""
    logging.basicConfig(
        level=logging.DEBUG,
        format='%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s',
        handlers=[
            logging.StreamHandler(sys.stdout),
            logging.FileHandler('debug.log')
        ]
    )
```

### 2. ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°
```python
# utils/profiling.py
import cProfile
import pstats
from functools import wraps

def profile_function(func):
    """é–¢æ•°å®Ÿè¡Œæ™‚é–“ã‚’æ¸¬å®šã™ã‚‹ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        profiler = cProfile.Profile()
        profiler.enable()
        
        try:
            result = func(*args, **kwargs)
        finally:
            profiler.disable()
            stats = pstats.Stats(profiler)
            stats.sort_stats('cumulative')
            stats.print_stats(10)  # ä¸Šä½10ä»¶è¡¨ç¤º
        
        return result
    return wrapper
```

### 3. ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–
```python
# utils/memory_monitor.py
import psutil
import pandas as pd

def monitor_memory_usage(func):
    """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ç›£è¦–ã™ã‚‹ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        process = psutil.Process()
        memory_before = process.memory_info().rss / 1024 / 1024  # MB
        
        result = func(*args, **kwargs)
        
        memory_after = process.memory_info().rss / 1024 / 1024  # MB
        memory_diff = memory_after - memory_before
        
        print(f"Memory usage: {memory_before:.1f}MB -> {memory_after:.1f}MB (diff: {memory_diff:+.1f}MB)")
        
        return result
    return wrapper
```

## ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³

### 1. ãƒ–ãƒ©ãƒ³ãƒæˆ¦ç•¥
```
main           # æœ¬ç•ªç”¨ãƒ–ãƒ©ãƒ³ãƒ
â”œâ”€â”€ develop    # é–‹ç™ºç”¨ãƒ–ãƒ©ãƒ³ãƒ
â”œâ”€â”€ feature/*  # æ©Ÿèƒ½é–‹ç™ºãƒ–ãƒ©ãƒ³ãƒ
â”œâ”€â”€ bugfix/*   # ãƒã‚°ä¿®æ­£ãƒ–ãƒ©ãƒ³ãƒ
â””â”€â”€ hotfix/*   # ç·Šæ€¥ä¿®æ­£ãƒ–ãƒ©ãƒ³ãƒ
```

### 2. ã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¦ç´„
```
type(scope): subject

body

footer

# ä¾‹
feat(batch): æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿å‡¦ç†æ©Ÿèƒ½ã‚’è¿½åŠ 

- SQLã‚¯ã‚¨ãƒªã®ä¸¦åˆ—å®Ÿè¡Œã‚’å®Ÿè£…
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’æ”¹å–„
- ãƒ­ã‚°å‡ºåŠ›ã‚’è©³ç´°åŒ–

Closes #123
```

### 3. ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆ ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ
- [ ] ãƒ†ã‚¹ãƒˆãŒé€šéã—ã¦ã„ã‚‹
- [ ] ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒå®Œäº†ã—ã¦ã„ã‚‹
- [ ] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒæ›´æ–°ã•ã‚Œã¦ã„ã‚‹
- [ ] å¾Œæ–¹äº’æ›æ€§ãŒä¿ãŸã‚Œã¦ã„ã‚‹
- [ ] ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¸Šã®å•é¡ŒãŒãªã„

### 4. ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ ãƒã‚¤ãƒ³ãƒˆ
- ã‚³ãƒ¼ãƒ‰ã®å¯èª­æ€§ãƒ»ä¿å®ˆæ€§
- ãƒ†ã‚¹ãƒˆã®ç¶²ç¾…æ€§
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¸ã®å½±éŸ¿
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¸Šã®å•é¡Œ
- è¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®é©ç”¨

## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### 1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–
```python
# æ¥ç¶šãƒ—ãƒ¼ãƒ«ä½¿ç”¨ä¾‹
from sqlalchemy import create_engine
from sqlalchemy.pool import QueuePool

engine = create_engine(
    connection_string,
    poolclass=QueuePool,
    pool_size=10,
    max_overflow=20,
    pool_pre_ping=True
)
```

### 2. ä¸¦åˆ—å‡¦ç†
```python
# ä¸¦åˆ—ãƒ‡ãƒ¼ã‚¿å‡¦ç†ä¾‹
import concurrent.futures
import pandas as pd

def process_sql_files_parallel(sql_files, max_workers=5):
    """SQLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸¦åˆ—å‡¦ç†"""
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_file = {
            executor.submit(process_sql_file, sql_file): sql_file 
            for sql_file in sql_files
        }
        
        results = []
        for future in concurrent.futures.as_completed(future_to_file):
            sql_file = future_to_file[future]
            try:
                result = future.result()
                results.append(result)
            except Exception as e:
                logger.error(f"Error processing {sql_file}: {e}")
        
        return results
```

### 3. ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
```python
# ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã«ã‚ˆã‚‹å¤§å®¹é‡ãƒ‡ãƒ¼ã‚¿å¯¾å¿œ
def process_large_dataset(query, chunk_size=10000):
    """å¤§å®¹é‡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒãƒ£ãƒ³ã‚¯å‡¦ç†"""
    offset = 0
    while True:
        chunk_query = f"{query} LIMIT {chunk_size} OFFSET {offset}"
        chunk_df = pd.read_sql(chunk_query, connection)
        
        if chunk_df.empty:
            break
            
        yield chunk_df
        offset += chunk_size
```